{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to normalise for minimised variables\n",
    "def normalisationmin(i):\n",
    "    return (i-i.min())/(i.max()-i.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to normalise for maximised variables\n",
    "def normalisationmax(i):\n",
    "    return (i-i.max())/(i.min()-i.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimisation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Import Pareto optimal results. \n",
    "Enter file name containing results, and number of rows to skip before headers using header = x. 1 row of headers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data file given here is for water grid case study, 5 year planning period, \n",
    "    #non-dominated results of 5 seeds, optimised using NSGA-II algorithm\n",
    "opdata = pd.read_csv(\"Data/optimisation results 5 combined seeds.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First column contains option number. Removing first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.drop(opdata.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cleanup data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cleanup data headings: Remove $ and . from column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.rename(columns = lambda x: x.replace('$', ''), inplace = True)\n",
    "opdata.rename(columns = lambda x: x.replace('.', ''), inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convert units (select columns to divide by 1,000 or 1,000,000 to make more appropriate units.\n",
    "Also fix negated objectives. \n",
    "Ensure to update column numbers when new results are input.\n",
    "Headings changed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert storage to GL and absolute value\n",
    "opdata[opdata.columns[16:18]] = abs(opdata[opdata.columns[16:18]]/1000)\n",
    "\n",
    "# convert to $ million\n",
    "opdata[opdata.columns[18:24]] = opdata[opdata.columns[18:24]]/1000000\n",
    "\n",
    "# convert spill to GL\n",
    "opdata[opdata.columns[24:27]] = opdata[opdata.columns[24:27]]/1000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rename columns using list of replacement columns if desired. \n",
    "To print a list of column names for editing, use print(list(opdata.columns.values)) before replacing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XTwoWayPipelinesNPI2NPI2Threshold', 'XTwoWayPipelinesNPI2NPI2FlowThreshold', 'XTwoWayPipelinesNPINPIThreshold', 'XTwoWayPipelinesNPINPIFlowThreshold', 'XTwoWayPipelinesBrisbanetoNthPineInterconnectorBrisbanetoNthPineThreshold', 'XTwoWayPipelinesBrisbanetoNthPineInterconnectorBrisbanetoNthPineFlowThreshold', 'XTwoWayPipelinesMaroochytoBaroonInterconnectorMaroochytoBaroonThreshold', 'XTwoWayPipelinesEwenMaddocktoBaroonInterconnectorEwenMaddocktoBaroonThreshold', 'XTwoWayPipelinesEPIEPIThreshold', 'XTwoWayPipelinesEPIEPIFlowThreshold', 'XTwoWayPipelinesSPISPIThreshold', 'XTwoWayPipelinesSPISPIFlowThreshold', 'XWCRWSPRWThreshold', 'XTugunDesalinationTugunDesalOneThirdThreshold', 'XTugunDesalinationTugunDesalTwoThirdsThreshold', 'XTugunDesalinationTugunDesalFullThreshold', 'XSpillVolumesTotalSpillVolume', 'XMinimumSystemStorageNegation', 'XCostsTotalCost', 'XCostsSwitchingCost', 'XCostsPumpingCost', 'XCostsTugunDesalCost', 'XCostsTreatmentCost', 'XCostsPRWCost', 'XTugunDesalinationTugunDesalProductionTotal', 'XWCRWSPRWInflow', 'XTwoWayPipelinesTwoWayPipelineFlows', 'XSwitchCountsTotalSwitchCount', 'XSwitchCountsBrisbanetoNthPineSwitchCount', 'XSwitchCountsEPISwitchCount', 'XSwitchCountsEwentoBaroonSwitchCount', 'XSwitchCountsMaroochytoBaroonSwitchCount', 'XSwitchCountsNPI2SwitchCount', 'XSwitchCountsNPISwitchCount', 'XSwitchCountsSPISwitchCount', 'XEnvironmentalFlowsEnvFlowDeficit', 'XReliabilityTotalVolumetricReliability']\n"
     ]
    }
   ],
   "source": [
    "print(list(opdata.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replacementcolumns = ['NPI2 Threshold', 'NPI2 Flow Threshold', 'NPI Threshold', 'NPI Flow Threshold', \n",
    "                      'Brisbane to Nth Pine Threshold', 'Brisbane to Nth Pine Flow Threshold', 'Maroochy to Baroon Threshold', \n",
    "                      'Ewen Maddock to Baroon Threshold', 'EPI Threshold', 'EPI Flow Threshold', 'SPI Threshold', \n",
    "                      'SPI Flow Threshold', 'PRW Threshold', 'Desalination 1/3 Production Threshold', \n",
    "                      'Desalination 2/3 Production Threshold', 'Desalination Full Production Threshold', \n",
    "                      'Total Spill Volume (GL)', 'Minimum System Storage (GL)', 'Total Cost ($ million)', \n",
    "                      'Switching Cost ($ million)', 'Pumping Cost ($ million)', 'Desalination Cost ($ million)', \n",
    "                      'Treatment Cost ($ million)', 'PRW Cost ($ million)', 'Desalination Total Production Volume (GL)', \n",
    "                      'PRW Inflow (GL)', 'Two Way Pipeline Flow (GL)', 'Total Switch Count', 'Brisbane to Nth Pine Switch Count', \n",
    "                      'EPI Switch Count', 'Ewen to Baroon Switch Count', 'Maroochy to Baroon Switch Count', 'NPI2 Switch Count', \n",
    "                      'NPI Switch Count', 'SPI Switch Count', 'Environmental Flow Deficit', 'Total Volumetric Reliability']\n",
    "\n",
    "\n",
    "if len(replacementcolumns) != len(opdata.columns):\n",
    "    print 'replacement columns do not match length of original columns'\n",
    "\n",
    "for i in range(len(opdata.columns)):\n",
    "    opdata.rename(columns={opdata.columns[i]:replacementcolumns[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Save formatted Pareto set (inc. to pickle for use by other notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.to_pickle(\"Data/opdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.to_csv(\"Data/opdata.csv\", index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Extract Pareto set objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj1 = opdata['Minimum System Storage (GL)']\n",
    "obj1name = obj1.name\n",
    "obj2 = opdata['Total Cost ($ million)']\n",
    "obj2name = obj2.name\n",
    "obj3 = opdata['Total Spill Volume (GL)']\n",
    "obj3name = obj3.name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Save Pareto set objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objdict = {obj1name: obj1, obj2name: obj2, obj3name: obj3}\n",
    "\n",
    "objdf = pd.DataFrame(objdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj1.to_pickle(\"Data/obj1\")\n",
    "obj2.to_pickle(\"Data/obj2\")\n",
    "obj3.to_pickle(\"Data/obj3\")\n",
    "\n",
    "objdf.to_pickle(\"Data/objdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Extract and save Pareto set decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter titles/order of decision variables to create data frame\n",
    "dvdf = pd.DataFrame(opdata, columns = ['NPI2 Threshold', 'NPI2 Flow Threshold', 'NPI Threshold', 'NPI Flow Threshold', \n",
    "                                        'Brisbane to Nth Pine Threshold', 'Brisbane to Nth Pine Flow Threshold', \n",
    "                                        'Maroochy to Baroon Threshold', 'Ewen Maddock to Baroon Threshold', \n",
    "                                        'EPI Threshold', 'EPI Flow Threshold', 'SPI Threshold', \n",
    "                                        'SPI Flow Threshold', 'PRW Threshold', 'Desalination 1/3 Production Threshold', \n",
    "                                        'Desalination 2/3 Production Threshold', 'Desalination Full Production Threshold',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdf.to_pickle(\"Data/dvdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Normalise objectives and save\n",
    "Normalisation with 0 as preferred/ideal value, 1 as least preferred/non-ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create new column/chart names for normalised objectives, with units removed and newlines\n",
    "normcols = ['Minimum\\nSystem Storage', 'Total Cost', 'Total\\nSpill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normobj1 = normalisationmax(obj1)\n",
    "normobj2 = normalisationmin(obj2)\n",
    "normobj3 = normalisationmin(obj3)\n",
    "\n",
    "#create dataframe that preserves order of objectives\n",
    "normobjdf = pd.DataFrame.from_items([(normcols[0], normobj1), (normcols[1], normobj2), (normcols[2], normobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normobjdf.to_pickle(\"Data/normobjdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1-norm objectives and save\n",
    "Normalisation with 1 as preferred/ideal value, 0 as least preferred/non-ideal\n",
    "Used in compromise programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onenormobj1 = normalisationmin(obj1)\n",
    "onenormobj2 = normalisationmax(obj2)\n",
    "onenormobj3 = normalisationmax(obj3)\n",
    "\n",
    "#create dataframe that preserves order of objectives\n",
    "onenormobjdf = pd.DataFrame.from_items([(obj1name, onenormobj1), \n",
    "                                        (obj2name, onenormobj2),\n",
    "                                        (obj3name, onenormobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onenormobj1.to_pickle(\"Data/onenormobj1\")\n",
    "onenormobj2.to_pickle(\"Data/onenormobj2\")\n",
    "onenormobj3.to_pickle(\"Data/onenormobj3\")\n",
    "\n",
    "onenormobjdf.to_pickle(\"Data/onenormobjdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import and format cluster results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Medoids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Enter objective function medoids (cluster representatives), from cluster analysis. \n",
    "For case study, cluster analysis was done using R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medoids = pd.read_csv('Data/medoids.csv', header = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create dataframe of objective function medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medobj1 = medoids['Minimum System Storage (GL)']\n",
    "medobj2 = medoids['Total Cost ($ million)']\n",
    "medobj3 = medoids['Total Spill Volume (GL)']\n",
    "\n",
    "medobjdf = pd.DataFrame.from_items([(medobj1.name, medobj1), (medobj2.name, medobj2), (medobj3.name, medobj3)])\n",
    "\n",
    "# Identify option number (index) of medoids within wider Pareto set\n",
    "medindex = medoids['Option']-1 # converting R index of medoids (starts at 1) to python index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Save objective function medoids to pickle for use by other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medobj1.to_pickle(\"Data/medobj1\")\n",
    "medobj2.to_pickle(\"Data/medobj2\")\n",
    "medobj3.to_pickle(\"Data/medobj3\")\n",
    "\n",
    "medobjdf.to_pickle(\"Data/medobjdf\")\n",
    "\n",
    "medindex.to_pickle(\"Data/medindex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Normalise medoids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Normalise medoids, with 0 being preferred value, 1 least preferred \n",
    "Relative to max or min, need to change equations below to suit maximum or minimised objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedobj1 = (medobj1-obj1.max())/(obj1.min()-obj1.max()) #maximised obj\n",
    "normmedobj2 = (medobj2-obj2.min())/(obj2.max()-obj2.min()) #minimised obj\n",
    "normmedobj3 = (medobj3-obj3.min())/(obj3.max()-obj3.min()) #minimised obj"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Format normalised medoid data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoidobjdf = pd.DataFrame({obj1name: normmedobj1, obj2name: normmedobj2,\n",
    "                         obj3name: normmedobj3})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Save to pickle for use by other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoidobjdf.to_pickle(\"Data/normmedoidobjdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Normalise medoid decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoiddvdf = pd.DataFrame(index = range(0, len(medindex)), columns = dvdf.columns)\n",
    "for i in range(0, len(medindex)):\n",
    "    for j in dvdf.columns:\n",
    "        normmedoiddvdf.ix[i,j] = (dvdf.ix[medindex[i],j]-dvdf[j].min())/(dvdf[j].max()-dvdf[j].min())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create dataframe of combined normalised objective functions and decision variables of medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoiddf = pd.concat([normmedoiddvdf, normmedoidobjdf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoiddf.to_pickle(\"Data/normmedoiddf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cluster mapping (cluster membership of each option)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Import cluster mapping: identifies cluster membership of each decision option in the Pareto set. Rows should correspond to the same options as the opdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusternos = pd.read_csv('Data/clusternos.csv', usecols = [1], header = 0, names = ['Cluster']) \n",
    "    #importing cluster numbers from R results. This needs to be updated when opdata is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusternos.to_pickle(\"Data/clusternos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Set cluster colours for plotting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create colour pool for clusters (add colours to taste, depending on number of clusters)\n",
    "Using this pool allows consistency between plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcols = pd.Series(['brown', 'red', 'magenta', 'yellow', 'aqua', 'Green', \n",
    "          'SteelBlue', 'Navy', 'purple', 'Gray', 'Black'], name = 'Cluster Colours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcols.to_pickle(\"Data/clustercolours\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create list of colours for plotting, one for each decision option/index. Ensure colorpool is applied in the same order to each option/cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcollist = []\n",
    "for i in clusternos.index:\n",
    "    clustcollist.append(clustcols[clusternos['Cluster'][i]-1])\n",
    "clustcolseries = pd.Series(clustcollist, name = 'Cluster Colour List')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcolseries.to_pickle(\"Data/clustcollist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create shortlist of options based on results visual and post-optimisation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter row numbers of shortlist for selecting shortlisted solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Enter row numbers of shorlisted solutions, remember in Python they start at 0\n",
    "\n",
    "shortlist_rows = [medindex[2-1], medindex[9-1], medindex[10-1], obj2.idxmin(), 471, 672, 670, 295, 348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218, 509, 138, 405, 471, 672, 670, 295, 348]\n"
     ]
    }
   ],
   "source": [
    "print shortlist_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create category to identify shortlist and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlist_decider = lambda value: \"Option %d\" % (x+1) if value in shortlist_rows else \"Other option\"\n",
    "shortlist = pd.DataFrame({'Shortlist':[shortlist_decider(x) for x in xrange(len(opdata))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlist.to_pickle(\"Data/shortlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of shortlist data and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdf = pd.DataFrame(opdata.ix[shortlist_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdf.to_pickle(\"Data/shortlistdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to csv, with decision options as columns instead of rows and converted to start from 1 (instead of python 0-index). Used for presentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdftf = pd.DataFrame(index = shortlistdf.columns, columns = shortlistdf.index+1)\n",
    "for i in shortlistdf.columns:\n",
    "    for j in shortlistdf.index:\n",
    "        shortlistdftf.loc[i,j+1] = str(\"%.2f\") % shortlistdf.loc[j,i]\n",
    "shortlistdftf.to_csv(\"Data/shortlist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise shortlist objective functions and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortobj1 = (shortlistdf['Minimum System Storage (GL)']-obj1.max())/(obj1.min()-obj1.max())\n",
    "normshortobj2 = (shortlistdf['Total Cost ($ million)']-obj2.min())/(obj2.max()-obj2.min())\n",
    "normshortobj3 = (shortlistdf['Total Spill Volume (GL)']-obj3.min())/(obj3.max()-obj3.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortlistobjdf = pd.DataFrame.from_items([(obj1name, normshortobj1), \n",
    "                                           (obj2name, normshortobj2), \n",
    "                                           (obj3name, normshortobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortlistobjdf.to_pickle(\"Data/normshortlistobjdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
