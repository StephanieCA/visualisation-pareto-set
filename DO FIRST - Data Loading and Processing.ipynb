{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to normalise for minimised variables\n",
    "def normalisationmin(i):\n",
    "    return (i-i.min())/(i.max()-i.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to normalise for maximised variables\n",
    "def normalisationmax(i):\n",
    "    return (i-i.max())/(i.min()-i.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimisation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pareto optimal results. \n",
    "Enter file name containing results, and number of rows to skip before headers using header = x. 1 row of headers only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data file given here is for the water grid case study documented in the accompanying paper, with a 5 year planning period, non-dominated results of 5 seeds, optimised using NSGA-II algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata = pd.read_csv(\"Data/optimisation results 5 combined seeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First column contains option number. Removing first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.drop(opdata.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cleanup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup data headings: Remove $ and . from column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.rename(columns = lambda x: x.replace('$', ''), inplace = True)\n",
    "opdata.rename(columns = lambda x: x.replace('.', ''), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert units (select columns to divide by 1,000 or 1,000,000 to make more appropriate units.\n",
    "Also fix negated objectives. \n",
    "Ensure to update column numbers when new results are input.\n",
    "Headings changed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert storage to GL and absolute value\n",
    "opdata[opdata.columns[16:18]] = abs(opdata[opdata.columns[16:18]]/1000)\n",
    "\n",
    "# convert to $ million\n",
    "opdata[opdata.columns[18:24]] = opdata[opdata.columns[18:24]]/1000000\n",
    "\n",
    "# convert spill to GL\n",
    "opdata[opdata.columns[24:27]] = opdata[opdata.columns[24:27]]/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns using list of replacement columns if desired. \n",
    "To print a list of column names for editing, use print(list(opdata.columns.values)) before replacing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XTwoWayPipelinesNPI2NPI2Threshold', 'XTwoWayPipelinesNPI2NPI2FlowThreshold', 'XTwoWayPipelinesNPINPIThreshold', 'XTwoWayPipelinesNPINPIFlowThreshold', 'XTwoWayPipelinesBrisbanetoNthPineInterconnectorBrisbanetoNthPineThreshold', 'XTwoWayPipelinesBrisbanetoNthPineInterconnectorBrisbanetoNthPineFlowThreshold', 'XTwoWayPipelinesMaroochytoBaroonInterconnectorMaroochytoBaroonThreshold', 'XTwoWayPipelinesEwenMaddocktoBaroonInterconnectorEwenMaddocktoBaroonThreshold', 'XTwoWayPipelinesEPIEPIThreshold', 'XTwoWayPipelinesEPIEPIFlowThreshold', 'XTwoWayPipelinesSPISPIThreshold', 'XTwoWayPipelinesSPISPIFlowThreshold', 'XWCRWSPRWThreshold', 'XTugunDesalinationTugunDesalOneThirdThreshold', 'XTugunDesalinationTugunDesalTwoThirdsThreshold', 'XTugunDesalinationTugunDesalFullThreshold', 'XSpillVolumesTotalSpillVolume', 'XMinimumSystemStorageNegation', 'XCostsTotalCost', 'XCostsSwitchingCost', 'XCostsPumpingCost', 'XCostsTugunDesalCost', 'XCostsTreatmentCost', 'XCostsPRWCost', 'XTugunDesalinationTugunDesalProductionTotal', 'XWCRWSPRWInflow', 'XTwoWayPipelinesTwoWayPipelineFlows', 'XSwitchCountsTotalSwitchCount', 'XSwitchCountsBrisbanetoNthPineSwitchCount', 'XSwitchCountsEPISwitchCount', 'XSwitchCountsEwentoBaroonSwitchCount', 'XSwitchCountsMaroochytoBaroonSwitchCount', 'XSwitchCountsNPI2SwitchCount', 'XSwitchCountsNPISwitchCount', 'XSwitchCountsSPISwitchCount', 'XEnvironmentalFlowsEnvFlowDeficit', 'XReliabilityTotalVolumetricReliability']\n"
     ]
    }
   ],
   "source": [
    "print(list(opdata.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replacementcolumns = ['NPI2 Threshold', 'NPI2 Flow Threshold', 'NPI Threshold', 'NPI Flow Threshold', \n",
    "                      'Brisbane to Nth Pine Threshold', 'Brisbane to Nth Pine Flow Threshold', 'Maroochy to Baroon Threshold', \n",
    "                      'Ewen Maddock to Baroon Threshold', 'EPI Threshold', 'EPI Flow Threshold', 'SPI Threshold', \n",
    "                      'SPI Flow Threshold', 'PRW Threshold', 'Desalination 1/3 Production Threshold', \n",
    "                      'Desalination 2/3 Production Threshold', 'Desalination Full Production Threshold', \n",
    "                      'Total Spill Volume (GL)', 'Minimum System Storage (GL)', 'Total Cost ($ million)', \n",
    "                      'Switching Cost ($ million)', 'Pumping Cost ($ million)', 'Desalination Cost ($ million)', \n",
    "                      'Treatment Cost ($ million)', 'PRW Cost ($ million)', 'Desalination Total Production Volume (GL)', \n",
    "                      'PRW Inflow (GL)', 'Two Way Pipeline Flow (GL)', 'Total Switch Count', 'Brisbane to Nth Pine Switch Count', \n",
    "                      'EPI Switch Count', 'Ewen to Baroon Switch Count', 'Maroochy to Baroon Switch Count', 'NPI2 Switch Count', \n",
    "                      'NPI Switch Count', 'SPI Switch Count', 'Environmental Flow Deficit', 'Total Volumetric Reliability']\n",
    "\n",
    "\n",
    "if len(replacementcolumns) != len(opdata.columns):\n",
    "    print 'replacement columns do not match length of original columns'\n",
    "\n",
    "for i in range(len(opdata.columns)):\n",
    "    opdata.rename(columns={opdata.columns[i]:replacementcolumns[i]}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Save formatted Pareto set (inc. to pickle for use by other notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.to_pickle(\"Data/opdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opdata.to_csv(\"Data/opdata.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Pareto set objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj1 = opdata['Minimum System Storage (GL)']\n",
    "obj1name = obj1.name\n",
    "obj2 = opdata['Total Cost ($ million)']\n",
    "obj2name = obj2.name\n",
    "obj3 = opdata['Total Spill Volume (GL)']\n",
    "obj3name = obj3.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Pareto set objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objdict = {obj1name: obj1, obj2name: obj2, obj3name: obj3}\n",
    "\n",
    "objdf = pd.DataFrame(objdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj1.to_pickle(\"Data/obj1\")\n",
    "obj2.to_pickle(\"Data/obj2\")\n",
    "obj3.to_pickle(\"Data/obj3\")\n",
    "\n",
    "objdf.to_pickle(\"Data/objdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and save Pareto set decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter titles/order of decision variables to create data frame\n",
    "dvdf = pd.DataFrame(opdata, columns = ['NPI2 Threshold', 'NPI2 Flow Threshold', 'NPI Threshold', 'NPI Flow Threshold', \n",
    "                                        'Brisbane to Nth Pine Threshold', 'Brisbane to Nth Pine Flow Threshold', \n",
    "                                        'Maroochy to Baroon Threshold', 'Ewen Maddock to Baroon Threshold', \n",
    "                                        'EPI Threshold', 'EPI Flow Threshold', 'SPI Threshold', \n",
    "                                        'SPI Flow Threshold', 'PRW Threshold', 'Desalination 1/3 Production Threshold', \n",
    "                                        'Desalination 2/3 Production Threshold', 'Desalination Full Production Threshold',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdf.to_pickle(\"Data/dvdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise objectives and save\n",
    "\n",
    "Normalisation with 0 as preferred/ideal value, 1 as least preferred/non-ideal\n",
    "\n",
    "Used for decision maps, line diagram, radar chart and parallel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create new column/chart names for normalised objectives, with units removed and newlines\n",
    "normcols = ['Minimum\\nSystem Storage', 'Total Cost', 'Total\\nSpill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normobj1 = normalisationmax(obj1)\n",
    "normobj2 = normalisationmin(obj2)\n",
    "normobj3 = normalisationmin(obj3)\n",
    "\n",
    "#create dataframe that preserves order of objectives\n",
    "normobjdf = pd.DataFrame.from_items([(normcols[0], normobj1), (normcols[1], normobj2), (normcols[2], normobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normobjdf.to_pickle(\"Data/normobjdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-normalise objectives and save\n",
    "\n",
    "Normalisation with 1 as preferred/ideal value, 0 as least preferred/non-ideal\n",
    "\n",
    "Used in compromise programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onenormobj1 = normalisationmin(obj1)\n",
    "onenormobj2 = normalisationmax(obj2)\n",
    "onenormobj3 = normalisationmax(obj3)\n",
    "\n",
    "#create dataframe that preserves order of objectives\n",
    "onenormobjdf = pd.DataFrame.from_items([(obj1name, onenormobj1), \n",
    "                                        (obj2name, onenormobj2),\n",
    "                                        (obj3name, onenormobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onenormobj1.to_pickle(\"Data/onenormobj1\")\n",
    "onenormobj2.to_pickle(\"Data/onenormobj2\")\n",
    "onenormobj3.to_pickle(\"Data/onenormobj3\")\n",
    "\n",
    "onenormobjdf.to_pickle(\"Data/onenormobjdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import and format cluster results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Medoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter objective function medoids (cluster representatives), from cluster analysis. \n",
    "\n",
    "For case study, cluster analysis was done using R. (see ClusterAnalysis.R)\n",
    "\n",
    "There are 3 cluster sets for the case study, based on values of: objectives, decision variables, and objectives + decision variables respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clusters based on objectives\n",
    "medoids = pd.read_csv('Data/medoids.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters based on decision variables\n",
    "dvmedoids = pd.read_csv('Data/dvmedoids.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters based on objectives and decision variables\n",
    "allmedoids = pd.read_csv('Data/allmedoids.csv', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of objective function medoids\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clusters based on objectives\n",
    "\n",
    "medobj1 = medoids['Minimum System Storage (GL)']\n",
    "medobj2 = medoids['Total Cost ($ million)']\n",
    "medobj3 = medoids['Total Spill Volume (GL)']\n",
    "\n",
    "medobjdf = pd.DataFrame.from_items([(medobj1.name, medobj1), (medobj2.name, medobj2), (medobj3.name, medobj3)])\n",
    "\n",
    "# Identify option number (index) of medoids within wider Pareto set\n",
    "medindex = medoids['Option']-1 # converting R index of medoids (starts at 1) to python index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clusters based on decision variables\n",
    "\n",
    "# Identify option number (index) of medoids within wider Pareto set\n",
    "dvmedindex = dvmedoids['Option']-1 # converting R index of medoids (starts at 1) to python index\n",
    "\n",
    "dvmedobj1 = opdata.ix[dvmedindex,'Minimum System Storage (GL)']\n",
    "dvmedobj2 = opdata.ix[dvmedindex,'Total Cost ($ million)']\n",
    "dvmedobj3 = opdata.ix[dvmedindex,'Total Spill Volume (GL)']\n",
    "\n",
    "dvmedobjdf = pd.DataFrame.from_items([(dvmedobj1.name, dvmedobj1), \n",
    "                                      (dvmedobj2.name, dvmedobj2), \n",
    "                                      (dvmedobj3.name, dvmedobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters based on normalised objectives and decision variables combined\n",
    "\n",
    "allmedobj1 = allmedoids['Minimum System Storage (GL)']\n",
    "allmedobj2 = allmedoids['Total Cost ($ million)']\n",
    "allmedobj3 = allmedoids['Total Spill Volume (GL)']\n",
    "\n",
    "allmedobjdf = pd.DataFrame.from_items([(allmedobj1.name, allmedobj1), \n",
    "                                       (allmedobj2.name, allmedobj2), \n",
    "                                       (allmedobj3.name, allmedobj3)])\n",
    "\n",
    "# Identify option number (index) of medoids within wider Pareto set\n",
    "allmedindex = allmedoids['Option']-1 # converting R index of medoids (starts at 1) to python index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save objective function medoids to pickle for use by other notebooks\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medobj1.to_pickle(\"Data/medobj1\")\n",
    "medobj2.to_pickle(\"Data/medobj2\")\n",
    "medobj3.to_pickle(\"Data/medobj3\")\n",
    "\n",
    "medobjdf.to_pickle(\"Data/medobjdf\")\n",
    "\n",
    "medindex.to_pickle(\"Data/medindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dvmedobj1.to_pickle(\"Data/dvmedobj1\")\n",
    "dvmedobj2.to_pickle(\"Data/dvmedobj2\")\n",
    "dvmedobj3.to_pickle(\"Data/dvmedobj3\")\n",
    "\n",
    "dvmedobjdf.to_pickle(\"Data/dvmedobjdf\")\n",
    "\n",
    "dvmedindex.to_pickle(\"Data/dvmedindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allmedobj1.to_pickle(\"Data/allmedobj1\")\n",
    "allmedobj2.to_pickle(\"Data/allmedobj2\")\n",
    "allmedobj3.to_pickle(\"Data/allmedobj3\")\n",
    "\n",
    "allmedobjdf.to_pickle(\"Data/allmedobjdf\")\n",
    "\n",
    "allmedindex.to_pickle(\"Data/allmedindex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Normalise medoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise medoids, with 0 being preferred value, 1 least preferred \n",
    "\n",
    "Relative to max or min, need to change equations below to suit maximum or minimised objectives\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedobj1 = (medobj1-obj1.max())/(obj1.min()-obj1.max()) #maximised obj\n",
    "normmedobj2 = (medobj2-obj2.min())/(obj2.max()-obj2.min()) #minimised obj\n",
    "normmedobj3 = (medobj3-obj3.min())/(obj3.max()-obj3.min()) #minimised obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normdvmedobj1 = (dvmedobj1-obj1.max())/(obj1.min()-obj1.max()) #maximised obj\n",
    "normdvmedobj2 = (dvmedobj2-obj2.min())/(obj2.max()-obj2.min()) #minimised obj\n",
    "normdvmedobj3 = (dvmedobj3-obj3.min())/(obj3.max()-obj3.min()) #minimised obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normallmedobj1 = (allmedobj1-obj1.max())/(obj1.min()-obj1.max()) #maximised obj\n",
    "normallmedobj2 = (allmedobj2-obj2.min())/(obj2.max()-obj2.min()) #minimised obj\n",
    "normallmedobj3 = (allmedobj3-obj3.min())/(obj3.max()-obj3.min()) #minimised obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format normalised medoid data into dataframe\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoidobjdf = pd.DataFrame({obj1name: normmedobj1, obj2name: normmedobj2,\n",
    "                         obj3name: normmedobj3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normdvmedoidobjdf = pd.DataFrame({obj1name: normdvmedobj1, obj2name: normdvmedobj2,\n",
    "                         obj3name: normdvmedobj3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normallmedoidobjdf = pd.DataFrame({obj1name: normallmedobj1, obj2name: normallmedobj2,\n",
    "                         obj3name: normallmedobj3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to pickle for use by other scripts\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoidobjdf.to_pickle(\"Data/normmedoidobjdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normdvmedoidobjdf.to_pickle(\"Data/normdvmedoidobjdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normallmedoidobjdf.to_pickle(\"Data/normallmedoidobjdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise medoid decision variables\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoiddvdf = pd.DataFrame(index = range(0, len(medindex)), columns = dvdf.columns)\n",
    "for i in range(0, len(medindex)):\n",
    "    for j in dvdf.columns:\n",
    "        normmedoiddvdf.ix[i,j] = (dvdf.ix[medindex[i],j]-dvdf[j].min())/(dvdf[j].max()-dvdf[j].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normdvmedoiddvdf = pd.DataFrame(index = range(0, len(dvmedindex)), columns = dvdf.columns)\n",
    "for i in range(0, len(dvmedindex)):\n",
    "    for j in dvdf.columns:\n",
    "        normdvmedoiddvdf.ix[i,j] = (dvdf.ix[dvmedindex[i],j]-dvdf[j].min())/(dvdf[j].max()-dvdf[j].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normallmedoiddvdf = pd.DataFrame(index = range(0, len(allmedindex)), columns = dvdf.columns)\n",
    "for i in range(0, len(allmedindex)):\n",
    "    for j in dvdf.columns:\n",
    "        normallmedoiddvdf.ix[i,j] = (dvdf.ix[allmedindex[i],j]-dvdf[j].min())/(dvdf[j].max()-dvdf[j].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of combined normalised objective functions and decision variables of medoids and save to pickle\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normmedoiddf = pd.concat([normmedoiddvdf, normmedoidobjdf], axis = 1)\n",
    "normmedoiddf.to_pickle(\"Data/normmedoiddf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normdvmedoiddf = pd.concat([normdvmedoiddvdf, normdvmedoidobjdf], axis = 1)\n",
    "normdvmedoiddf.to_pickle(\"Data/normdvmedoiddf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normallmedoiddf = pd.concat([normallmedoiddvdf, normallmedoidobjdf], axis = 1)\n",
    "normallmedoiddf.to_pickle(\"Data/normallmedoiddf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cluster mapping (cluster membership of each option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cluster mapping: identifies cluster membership of each decision option in the Pareto set. \n",
    "\n",
    "Rows should correspond to the same options as the opdata.\n",
    "\n",
    "Save to pickle.\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusternos = pd.read_csv('Data/clusternos.csv', usecols = [1], header = 0, names = ['Cluster']) \n",
    "    #importing cluster numbers from R results. This needs to be updated when opdata is updated\n",
    "clusternos.to_pickle(\"Data/clusternos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvclusternos = pd.read_csv('Data/dvclusternos.csv', usecols = [1], header = 0, names = ['Cluster']) \n",
    "    #importing cluster numbers from R results. This needs to be updated when opdata is updated\n",
    "dvclusternos.to_pickle(\"Data/dvclusternos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allclusternos = pd.read_csv('Data/allclusternos.csv', usecols = [1], header = 0, names = ['Cluster']) \n",
    "    #importing cluster numbers from R results. This needs to be updated when opdata is updated\n",
    "allclusternos.to_pickle(\"Data/allclusternos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Set cluster colours for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create colour pool for clusters (add colours to taste, depending on number of clusters)\n",
    "\n",
    "Using this pool allows consistency between plots\n",
    "\n",
    "This clusterpool can be used for all 3 cluster sets of the case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcols = pd.Series(['brown', 'red', 'magenta', 'yellow', 'aqua', 'Green', \n",
    "          'SteelBlue', 'Navy', 'purple', 'Gray', 'Black'], name = 'Cluster Colours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustcols.to_pickle(\"Data/clustercolours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of colours for plotting, one for each decision option/index. Ensure colorpool is applied in the same order to each option/cluster.\n",
    "\n",
    "For each of the 3 cluster sets (objectives, decision variables, objectives + decision variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustcollist = []\n",
    "for i in clusternos.index:\n",
    "    clustcollist.append(clustcols[clusternos['Cluster'][i]-1])\n",
    "clustcolseries = pd.Series(clustcollist, name = 'Cluster Colour List')\n",
    "\n",
    "clustcolseries.to_pickle(\"Data/clustcollist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvclustcollist = []\n",
    "for i in dvclusternos.index:\n",
    "    dvclustcollist.append(clustcols[dvclusternos['Cluster'][i]-1])\n",
    "dvclustcolseries = pd.Series(dvclustcollist, name = 'Cluster Colour List')\n",
    "\n",
    "dvclustcolseries.to_pickle(\"Data/dvclustcollist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allclustcollist = []\n",
    "for i in allclusternos.index:\n",
    "    allclustcollist.append(clustcols[allclusternos['Cluster'][i]-1])\n",
    "allclustcolseries = pd.Series(allclustcollist, name = 'Cluster Colour List')\n",
    "\n",
    "allclustcolseries.to_pickle(\"Data/allclustcollist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Set cluster markers for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create marker pool for clusters (add markers to taste, depending on number of clusters)\n",
    "\n",
    "Using this pool allows consistency between plots, and allows plots to be presented in black and white\n",
    "\n",
    "For cluster set 1 only, since this is the only one presented in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustmarks = pd.Series([\"o\",\"v\",\"^\",\"<\",\">\",\"D\",\"s\",\"p\",\"*\",\"h\",\n",
    "              \"+\",\"x\",\"8\"], name = \"Cluster Markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustmarks.to_pickle(\"Data/clustermarkers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of markers for plotting, one for each decision option/index. Ensure markerpool is applied in the same order to each option/cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustmarklist = []\n",
    "for i in clusternos.index:\n",
    "    clustmarklist.append(clustmarks[clusternos['Cluster'][i]-1])\n",
    "clustmarkseries = pd.Series(clustmarklist, name = 'Cluster Marker List')\n",
    "\n",
    "clustmarkseries.to_pickle(\"Data/clustmarklist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create shortlist of options based on results visual and post-optimisation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter row numbers of shortlist for selecting shortlisted solution\n",
    "Remember in Python they start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlist_rows = [medindex[2-1], medindex[9-1], medindex[10-1], obj2.idxmin(), 471, 672, 670, 295, 348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218, 509, 138, 405, 471, 672, 670, 295, 348]\n"
     ]
    }
   ],
   "source": [
    "print shortlist_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create category to identify shortlist and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlist_decider = lambda value: \"Option %d\" % (x+1) if value in shortlist_rows else \"Other option\"\n",
    "shortlist = pd.DataFrame({'Shortlist':[shortlist_decider(x) for x in xrange(len(opdata))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlist.to_pickle(\"Data/shortlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of shortlist data and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdf = pd.DataFrame(opdata.ix[shortlist_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdf.to_pickle(\"Data/shortlistdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to csv, with decision options as columns instead of rows and converted to start from 1 (instead of python 0-index). Used for presentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortlistdftf = pd.DataFrame(index = shortlistdf.columns, columns = shortlistdf.index+1)\n",
    "for i in shortlistdf.columns:\n",
    "    for j in shortlistdf.index:\n",
    "        shortlistdftf.loc[i,j+1] = str(\"%.2f\") % shortlistdf.loc[j,i]\n",
    "shortlistdftf.to_csv(\"Data/shortlist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise shortlist objective functions and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortobj1 = (shortlistdf['Minimum System Storage (GL)']-obj1.max())/(obj1.min()-obj1.max())\n",
    "normshortobj2 = (shortlistdf['Total Cost ($ million)']-obj2.min())/(obj2.max()-obj2.min())\n",
    "normshortobj3 = (shortlistdf['Total Spill Volume (GL)']-obj3.min())/(obj3.max()-obj3.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortlistobjdf = pd.DataFrame.from_items([(obj1name, normshortobj1), \n",
    "                                           (obj2name, normshortobj2), \n",
    "                                           (obj3name, normshortobj3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normshortlistobjdf.to_pickle(\"Data/normshortlistobjdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
